#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–í—ã–≤–æ–¥–∏—Ç –≤—Å–µ –∞–Ω–æ–º–∞–ª–∏–∏ —Å —É–∫–∞–∑–∞–Ω–∏–µ–º —Ñ–∞–π–ª–∞ –∏ –Ω–æ–º–µ—Ä–∞ —Å—Ç—Ä–æ–∫–∏
"""

import re
from pathlib import Path
from collections import defaultdict

# –ö–∏—Ä–∏–ª–ª–∏—Ü–∞, —Ü–∏—Ñ—Ä—ã, –æ—Å–Ω–æ–≤–Ω—ã–µ –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è, –ø—Ä–æ–±–µ–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
RUSSIAN_CHARS = set('–ê–ë–í–ì–î–ï–Å–ñ–ó–ò–ô–ö–õ–ú–ù–û–ü–†–°–¢–£–§–•–¶–ß–®–©–™–´–¨–≠–Æ–Ø–∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è0123456789')
PUNCTUATION = set('.,;:!?-"()[]{}¬´¬ª‚Äî‚Äì‚Ä¶')
WHITESPACE = set(' \n\r\t')
ALLOWED_CHARS = RUSSIAN_CHARS | PUNCTUATION | WHITESPACE

# –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –Ω–∞–∑–≤–∞–Ω–∏–π –≥–ª–∞–≤
CHAPTER_PATTERNS = [
    r'^[IVXLCDM]+$',
    r'^–ì–õ–ê–í–ê\s+[IVXLCDM\d]+',
    r'^–ß–ê–°–¢–¨\s+[IVXLCDM\d]+',
    r'^[–ì–ß]\s*[IVXLCDM\d]+',
    r'^\d+$',
]

def is_likely_chapter_title(line):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏–µ–º –≥–ª–∞–≤—ã"""
    stripped = line.strip()
    if not stripped:
        return False
    
    for pattern in CHAPTER_PATTERNS:
        if re.match(pattern, stripped, re.IGNORECASE):
            return True
    
    if len(stripped) < 30 and stripped.isupper() and stripped.replace(' ', '').isalpha():
        return True
    
    return False

def find_anomalies_in_file(filepath):
    """–ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ –∞–Ω–æ–º–∞–ª–∏–∏ –≤ —Ñ–∞–π–ª–µ"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            lines = f.readlines()
    except UnicodeDecodeError:
        try:
            with open(filepath, 'r', encoding='cp1251') as f:
                lines = f.readlines()
        except Exception as e:
            return {'error': str(e)}
    except Exception as e:
        return {'error': str(e)}
    
    anomalies = {
        'tokens': [],  # –¢–æ–∫–µ–Ω—ã (base64)
        'multiple_unusual': [],  # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –Ω–µ–æ–±—ã—á–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
        'unusual_symbols': [],  # –û—Ç–¥–µ–ª—å–Ω—ã–µ –Ω–µ–æ–±—ã—á–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
        'latin_in_russian': []  # –õ–∞—Ç–∏–Ω–∏—Ü–∞ –≤ —Ä—É—Å—Å–∫–æ–º —Ç–µ–∫—Å—Ç–µ
    }
    
    token_pattern = re.compile(r'^[A-Za-z0-9+/=]{40,}$')
    
    for line_num, line in enumerate(lines, 1):
        stripped = line.strip()
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏ –Ω–∞–∑–≤–∞–Ω–∏—è –≥–ª–∞–≤
        if not stripped or is_likely_chapter_title(line):
            continue
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ç–æ–∫–µ–Ω—ã (base64)
        if token_pattern.match(stripped) and len(stripped) > 40:
            anomalies['tokens'].append((line_num, stripped[:100]))
            continue
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –Ω–µ–æ–±—ã—á–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –ø–æ–¥—Ä—è–¥
        if re.search(r'[^\w\s\u0400-\u04FF.,;:!?\-"()\[\]{}¬´¬ª‚Äî‚Äì‚Ä¶]{3,}', line):
            anomalies['multiple_unusual'].append((line_num, stripped[:150]))
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–µ–æ–±—ã—á–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –∏ –ª–∞—Ç–∏–Ω–∏—Ü—É
        has_russian = any(c in RUSSIAN_CHARS for c in line)
        suspicious_chars = []
        latin_chars = []
        
        for i, char in enumerate(line):
            if char not in ALLOWED_CHARS:
                if char.isalpha() and ord(char) < 128:
                    latin_chars.append((i, char))
                else:
                    suspicious_chars.append((i, char, hex(ord(char))))
        
        if has_russian:
            if latin_chars and len(latin_chars) > 5:
                anomalies['latin_in_russian'].append((line_num, stripped[:150]))
            if suspicious_chars:
                anomalies['unusual_symbols'].append((line_num, stripped[:150]))
    
    return anomalies

def main():
    script_dir = Path(__file__).parent
    txt_files = sorted(script_dir.glob('*.txt'))
    
    # –ò—Å–∫–ª—é—á–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Ñ–∞–π–ª—ã
    exclude_files = {'find_anomalies.py', 'create_summary.py', 'show_all_anomalies.py',
                     'anomalies_report.txt', 'summary_report.txt', 'analysis_output.txt'}
    txt_files = [f for f in txt_files if f.name not in exclude_files]
    
    print("="*80)
    print("–í–°–ï –ê–ù–û–ú–ê–õ–ò–ò –° –£–ö–ê–ó–ê–ù–ò–ï–ú –°–¢–†–û–ö")
    print("="*80)
    print()
    
    total_files_with_anomalies = 0
    
    for txt_file in txt_files:
        anomalies = find_anomalies_in_file(txt_file)
        
        if 'error' in anomalies:
            continue
        
        has_any = any(anomalies[key] for key in anomalies)
        if not has_any:
            continue
        
        total_files_with_anomalies += 1
        print(f"\n{'='*80}")
        print(f"üìÑ {txt_file.name}")
        print('='*80)
        
        # –¢–æ–∫–µ–Ω—ã (–∫—Ä–∏—Ç–∏—á–Ω—ã–µ)
        if anomalies['tokens']:
            print(f"\nüî¥ –¢–û–ö–ï–ù–´ (BASE64) - {len(anomalies['tokens'])} —Å–ª—É—á–∞–µ–≤:")
            print("-"*80)
            for line_num, token in anomalies['tokens'][:20]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 20
                print(f"  –°—Ç—Ä–æ–∫–∞ {line_num:5d}: {token}...")
            if len(anomalies['tokens']) > 20:
                print(f"  ... –∏ –µ—â–µ {len(anomalies['tokens']) - 20} —Ç–æ–∫–µ–Ω–æ–≤")
        
        # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –Ω–µ–æ–±—ã—á–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
        if anomalies['multiple_unusual']:
            print(f"\n‚ö†Ô∏è  –ú–ù–û–ñ–ï–°–¢–í–ï–ù–ù–´–ï –ù–ï–û–ë–´–ß–ù–´–ï –°–ò–ú–í–û–õ–´ - {len(anomalies['multiple_unusual'])} —Å–ª—É—á–∞–µ–≤:")
            print("-"*80)
            for line_num, line in anomalies['multiple_unusual'][:15]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 15
                print(f"  –°—Ç—Ä–æ–∫–∞ {line_num:5d}: {line}...")
            if len(anomalies['multiple_unusual']) > 15:
                print(f"  ... –∏ –µ—â–µ {len(anomalies['multiple_unusual']) - 15} —Å–ª—É—á–∞–µ–≤")
        
        # –õ–∞—Ç–∏–Ω–∏—Ü–∞ –≤ —Ä—É—Å—Å–∫–æ–º —Ç–µ–∫—Å—Ç–µ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –º–Ω–æ–≥–æ)
        if len(anomalies['latin_in_russian']) > 10:
            print(f"\nüü° –õ–ê–¢–ò–ù–ò–¶–ê –í –†–£–°–°–ö–û–ú –¢–ï–ö–°–¢–ï - {len(anomalies['latin_in_russian'])} —Å–ª—É—á–∞–µ–≤:")
            print("-"*80)
            for line_num, line in anomalies['latin_in_russian'][:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
                print(f"  –°—Ç—Ä–æ–∫–∞ {line_num:5d}: {line}...")
            if len(anomalies['latin_in_russian']) > 10:
                print(f"  ... –∏ –µ—â–µ {len(anomalies['latin_in_russian']) - 10} —Å–ª—É—á–∞–µ–≤")
        
        # –ù–µ–æ–±—ã—á–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –º–Ω–æ–≥–æ –∏ –Ω–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤)
        if anomalies['unusual_symbols'] and not anomalies['tokens'] and len(anomalies['unusual_symbols']) > 20:
            print(f"\nüü† –ù–ï–û–ë–´–ß–ù–´–ï –°–ò–ú–í–û–õ–´ - {len(anomalies['unusual_symbols'])} —Å–ª—É—á–∞–µ–≤ (–ø–µ—Ä–≤—ã–µ 10):")
            print("-"*80)
            for line_num, line in anomalies['unusual_symbols'][:10]:
                print(f"  –°—Ç—Ä–æ–∫–∞ {line_num:5d}: {line}...")
    
    print(f"\n{'='*80}")
    print(f"–ò–¢–û–ì–û: –Ω–∞–π–¥–µ–Ω–æ –∞–Ω–æ–º–∞–ª–∏–π –≤ {total_files_with_anomalies} —Ñ–∞–π–ª–∞—Ö")
    print('='*80)

if __name__ == '__main__':
    main()

